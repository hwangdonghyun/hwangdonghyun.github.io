---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---
<!-- {% include base_path %} -->

# **Dong-Hyun Hwang, Ph.D.**

## **Research Interests**
- **Computer Vision and Machine Learning**  
  - Multi-modal Generative Models (Text-to-Image, Video, Motion, etc.)  
  - Large-scale Model Training and Engineering  
  - Human Pose Estimation  

- **Human-Computer Interaction**  
  - Interactive Systems using Computer Vision  
  - System Usability Evaluation and Statistical Analysis  

---

## **Professional Experience**

### **Research Engineer, NAVER Cloud**  
*01/2023 - Present*  
- **Team Lead of Hyperscale AI Model101 (2024 - Present)**  
  - Led a team of 4 to develop an AI Eraser Agent in CLOVA X, successfully launching the service.  
  - Contributed to a large-scale diffusion-based text-to-image training framework.  

- **Team Lead of Avatar (2023)**  
  - Directed a team of 6 in virtual human agent technology development.  
  - Recognized with the *N INNOVATION Award* for Outstanding Technology in R&D.  

### **Research Engineer, CLOVA, NAVER**  
*02/2022 - 12/2022*  
- Built a multi-view motion capture studio for high-precision 3D motion data.  
- Researched motion generation using generative AI models, focusing on motion augmentation and text-to-motion synthesis.  

### **Other Experiences**
- **JSPS Research Fellowship (DC2)** (04/2020 - 03/2022)  
- **Research Assistant**, Team Koike, JST (12/2018 - 03/2022)  
- **Program Chair**, ACM CHI2021 Workshop (04/2021)  
- **Visiting Scholar**, Kris Kitani Lab, Carnegie Mellon University (10/2019 - 01/2020)  

---

## **Education**

### **Tokyo Institute of Technology, Tokyo, Japan**  
- **Ph.D. in Computer Science** (04/2019 - 03/2022)  
  - *Thesis:* Markerless Human Motion Capture and Visualization from Monocular Videos  

- **M.S. in Computer Science** (04/2017 - 03/2019)  
  - *Thesis:* Synthesizing Pseudo-2.5D Content from Monocular Videos for Mixed Reality  

### **Korea University of Technology and Education, Korea**  
- **B.Sc. in Computer Engineering** (03/2010 - 02/2017)  
  - *Thesis:* A Pointing Device Using Hand Gesture Recognition (summa cum laude)  

---

## **Skills**
- **Programming Languages:** Python, C++  
- **Machine Learning Frameworks:** PyTorch, TensorFlow  
- **Tools:** OpenCV, Unity, FastAPI, Gradio  
- **Distributed Training:** PyTorch DDP, DeepSpeed  
- **Languages:** Korean (Native), Japanese (Fluent - JLPT N1), English (Advanced)  

---

## **Publications**
- [1] *Diffusion-based Synthetic Dataset Generation for Egocentric 3D Human Pose Estimation* (ECCV 2024 Workshop)  
- [3] *MonoEye: Multimodal Human Motion Capture System Using A Single Ultra-Wide Fisheye Camera* (UIST 2020)  
- [4] *Lightweight 3D Human Pose Estimation Network Training Using Teacher-Student Learning* (IEEE/CVF WACV 2020)  
*(Full list available upon request)*  

---

## **Awards & Grants**
- **N INNOVATION Award**, NAVER Corporation  
- **Grant-in-Aid for JSPS Fellows (KAKENHI Project)**  

---

## **Patents**
- **Motion Measurement Device** (JP2022007839A)  
- **Method for Generating Data for 3D Pose Estimation** (KR102562378B1, JP7178396B2, US11610331B2)  

---